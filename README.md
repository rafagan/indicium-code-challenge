## Indicium Code Challenge - Meltano Pipeline

# TODO: Instru√ß√µes gerais de como rodar os pipelines

Como este trabalho foi produzido:

### üèóÔ∏è 1. Organiza√ß√£o do Projeto
 - Cria√ß√£o das pastas do projeto.
 - Clone do reposit√≥rio [Indicium Code Challenge](https://github.com/techindicium/code-challenge).
 - Cria√ß√£o do **virtualenv**.
 - Instala√ß√£o do **Meltano**.

---

### üìÇ 2. Etapa 1: Extra√ß√£o do CSV e Exporta√ß√£o em JSONL (v1)

Vamos iniciar o desafio gerando o CSV a partir de order_details.csv para a pasta destino
/data/csv/yyyy-mm-dd/file.format

O modelo de arquivo escolhido foi jsonl pela facilidade de debugging das informa√ß√µes exportadas,
bem como por ser um formato bem conhecido pelos desenvolvedores e amplamente suportado pelo meltano
e outros ambientes de ETL. A vers√£o singer conserva dados de schema que facilitam a posterior insers√£o no loader
de banco de dados.

#### üõ†Ô∏è Instala√ß√£o dos Plugins
```bash
meltano add extractor tap-csv
meltano add loader target-singer-jsonl
meltano add loader target-singer-jsonl --as target-jsonl-csv
```

#### ‚öôÔ∏è Configura√ß√£o do tap-csv (Leitura do CSV order_details.csv)
```bash
meltano config tap-csv set files '[{
  "entity": "order_details",
  "path": "../../res/data/order_details.csv",
  "keys": ["order_id", "product_id", "unit_price", "quantity", "discount"]
}]'
```

#### ‚öôÔ∏è Configura√ß√£o do target-jsonl-csv (Escrita do JSONL do CSV)
```bash
meltano config target-jsonl-csv set destination "local"
meltano config target-jsonl-csv set local.folder "output/data/csv/$DATE"
```

#### üöÄ Cria√ß√£o do job de execu√ß√£o dos ETL
```bash
meltano job add csv-to-json --tasks 'tap-csv target-jsonl-csv'
```

#### üöÄ Execu√ß√£o do pipeline
```bash
DATE='2025-01-31' meltano run csv-to-json
```

---


### üìÇ 3. Etapa 1: Extra√ß√£o do banco de dados e Exporta√ß√£o em JSONL (v2)

A pr√≥xima etapa envolve extrair os dados de northwind.sql para a pasta destino
/data/postgres/{table}/yyyy-mm-dd/file.format.

#### üõ†Ô∏è Inicializa√ß√£o do banco de dados

A partir do docker-file.yml fornecido no projeto do desafio, vamos iniciar o banco. Na pasta res:

#### üõ†Ô∏è Instala√ß√£o banco de dados e defini√ß√£o das tabelas
```bash
docker compose up -d

TABLES=(
    'categories'
    'customer_customer_demo'
    'customer_demographics'
    'customers'
    'employee_territories'
    'employees'
    'orders'
    'products'
    'region'
    'shippers'
    'suppliers'
    'territories'
    'us_states'
)
```

#### ‚öôÔ∏è Configura√ß√£o do psql (Leitura do banco de dados northwind.sql)
```bash
meltano add extractor tap-postgres
meltano config tap-postgres set host "localhost"
meltano config tap-postgres set port "5432"
meltano config tap-postgres set database "northwind"
meltano config tap-postgres set user "northwind_user"
meltano config tap-postgres set password "thewindisblowing"
meltano config tap-postgres set state "enabled"
meltano config tap-postgres set state_id_suffix "latest"
meltano config tap-postgres set filter_schemas '["public"]'

STREAMS_JSON=$(printf '["%s"]' "$(IFS=','; echo "${TABLES[*]}" | sed 's/,/","/g')")
meltano config tap-postgres set selected_streams "$STREAMS_JSON"
```

#### ‚öôÔ∏è Configura√ß√£o do target-jsonl-psql-{table} (Escrita dos JSONL das tabelas)
```bash
for TABLE in "${TABLES[@]}"; do
    LOADER_NAME="target-jsonl-psql-$TABLE"
    
    meltano add loader "$LOADER_NAME" --inherit-from target-singer-jsonl
    meltano config "$LOADER_NAME" set destination "local"
    meltano config "$LOADER_NAME" set local.folder "output/data/postgres/$TABLE/\$DATE"
done

```

#### üöÄ Cria√ß√£o do job de execu√ß√£o dos ETL
```bash
TASKS_JSON="["
for TABLE in "${TABLES[@]}"; do
    TASKS_JSON+="\"tap-postgres target-jsonl-psql-$TABLE\", "
done

TASKS_JSON="${TASKS_JSON%, }]"
meltano job add psql-to-json --tasks "$TASKS_JSON"
```

#### üöÄ Execu√ß√£o do pipeline
```bash
DATE='2025-01-31' meltano run psql-to-json
```

---

### üìÇ 4. Etapa 2: Importa√ß√£o dos dados do filesystem no psql (v3)

Agora que todos os dados, tanto do CSV como do psql foram exportados para o filesystem (etapa 1),
respeitando uma estrutura de pastas. A etapa 2 ent√£o consiste em importar os dados dos arquivos
para tabelas de um novo banco de dados

#### üõ†Ô∏è Instala√ß√£o e configura√ß√£o loader psql
```bash
meltano add loader target-postgres
meltano config target-postgres set host "localhost"
meltano config target-postgres set port "5432"
meltano config target-postgres set database "northwind2"
meltano config target-postgres set user "northwind_user"
meltano config target-postgres set password "thewindisblowing"
meltano config target-postgres set default_target_schema public
```

#### ‚öôÔ∏è Cria√ß√£o tabela loader psql (no banco de dados)
```SQL
-- PGPASSWORD=thewindisblowing psql -h localhost -U northwind_user -d postgres
CREATE DATABASE northwind2;
```

#### üõ†Ô∏è Instala√ß√£o e configura√ß√£o extractor jsonl
```bash
meltano add extractor tap-singer-jsonl
meltano config tap-singer-jsonl set source local

JSON_FOLDERS="[
  \"output/data/postgres\",
  \"output/data/csv\"
]"

meltano config tap-singer-jsonl set local.recursive true
meltano config tap-singer-jsonl set local.folders "$JSON_FOLDERS"
```

#### üöÄ Cria√ß√£o do job de escrita no banco de dados psql do filesystem
```bash
meltano job add json-to-psql --tasks "tap-singer-jsonl target-postgres"
```

#### üöÄ Execu√ß√£o do pipeline
```bash
DATE='2025-01-31' meltano run json-to-psql
```

#### üì§ Para testar se a importa√ß√£o foi bem sucedida:
```bash
PGPASSWORD=thewindisblowing psql -h localhost -U northwind_user -d northwind2
northwind2-# \dt
northwind2=# SELECT * FROM orders LIMIT 10;
northwind2=# SELECT * FROM order_details LIMIT 10;

# Checar idempot√™ncia
SELECT COUNT(*) FROM orders;
SELECT COUNT(*) FROM order_details;
```

---

### üìÇ 4. Execu√ß√£o do pipeline em um orquestrador/scheduler (v4)

Seguindo os requisitos do trabalho, foi configurado o Apache Airflow para
executar o pipeline diariamente.

### a) Instala√ß√£o Airflow:

#### üõ†Ô∏è **Instala√ß√£o da utility Airflow**
```bash
meltano add utility airflow
meltano invoke airflow:initialize
```

#### ‚öôÔ∏è Configura√ß√£o de um usu√°rio Airflow
```bash
meltano invoke airflow users create -u admin -p admin --role Admin -e admin@admin.com -f admin -l admin
```

#### üì§ Para testar o usu√°rio na UI do Airflow e checar resultado da configura√ß√£o:
```bash
meltano invoke airflow webserver
```

### b) Agendar execu√ß√£o di√°ria:

#### ‚öôÔ∏è Configura√ß√£o de um meltano job para executar no Airflow scheduler:
```bash

TASKS=('"tap-csv target-jsonl-csv"')
for TABLE in "${TABLES[@]}"; do
    TASKS+=("\"tap-postgres target-jsonl-psql-${TABLE}\"")
done
TASKS+=('"tap-singer-jsonl target-postgres"')

TASKS_STR="[$(IFS=,; echo "${TASKS[*]}")]"
meltano job add filesystem-to-psql --tasks "$TASKS_STR"

meltano schedule add daily-filesystem-to-psql --job filesystem-to-psql --interval "@daily"
```

#### üöÄ Iniciar scheduler para execu√ß√£o de eventos agendados
```bash
MELTANO_ENVIRONMENT=dev meltano invoke airflow scheduler
```

#### üöÄ Ou execu√ß√£o manual e imediata do job
```bash
meltano run csv-to-json
```

---

### üìÇ 5. Query validando resultado final alcan√ßado

Vamos gerar um arquivo CSV a partir do psql que mostre as orders e seus detalhes (order_details)

#### üì§ Acessar banco de dados:
```bash
PGPASSWORD=thewindisblowing psql -h localhost -U northwind_user -d northwind2
```

#### üì§ Gerar arquivo:
```sql
\COPY (
    SELECT * from orders AS o 
    JOIN order_details AS d 
    ON o.order_id = CAST(d.order_id AS bigint)
) TO '/path/to/indicium/out/result.csv' WITH CSV HEADER;
```
